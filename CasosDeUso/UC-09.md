# UC-09: Autoaprendizado de Ameaças com IA Adaptativa (não é caso de uso)

## Caso de Uso Primário: UC-09: Autoaprendizado de Ameaças com IA Adaptativa

**Identificação do Caso de Uso Geral:** SistemaAntiMisseis-UC-09

**Resumo:**  
Este caso de uso descreve como a Plataforma de Inteligência Artificial do sistema antimísseis analisa dados históricos de detecção, 
resposta e classificação de ameaças para treinar e ajustar seus modelos. O objetivo é refinar continuamente os critérios de detecção e priorização, reduzindo falsos positivos e aumentando a eficácia do sistema ao longo do tempo.

**Ator Principal:**  
Plataforma de Inteligência Artificial

**Atores Secundários:**  
- Operador humano
- Sistema de Controle de Defesa
- Sensores


**Pré-condições:**  
- O sistema já registrou eventos anteriores de ameaças detectadas e classificadas.
- O módulo de aprendizado da Plataforma de IA está ativo e com acesso aos logs operacionais.
- O Operador humano está disponível para validações manuais, se necessárias.

**Pós-condições:**  
- O modelo de classificação de ameaças é atualizado.
- O sistema reduz o índice de falsos positivos.
- Relatórios de desempenho e mudanças são disponibilizados para o Operador humano.

## Cenário Principal

**Ações do Ator:**  
1. O Operador humano acessa os relatórios de detecção e classificação.
2. Valida ou corrige manualmente ameaças mal classificadas, quando necessário.
3. Autoriza a implantação de um novo modelo, se houver impacto significativo.

**Ações do Sistema:**  
1. A Plataforma de IA coleta os dados históricos de ameaças, decisões tomadas e resultados.
2. Executa o processo de aprendizado de máquina com base em padrões detectados.
3. Treina e valida internamente novos modelos de classificação.
4. Compara a performance do novo modelo com o modelo anterior.
5. Notifica o Sistema de Controle de Defesa e o Operador sobre a atualização.
6. Registra todo o ciclo de aprendizado, validação e implantação no log de auditoria.

## Regras de Negócio, Restrições e Validações

- Modelos só são implantados automaticamente se superarem os anteriores em no mínimo 10% de acurácia.
- Alterações significativas no classificador devem ser aprovadas pelo Operador humano.
- Logs de treinamento, avaliação e versão de modelo devem ser armazenados com rastreabilidade completa (RF13).
- O aprendizado deve respeitar limites computacionais para não comprometer a operação em tempo real.

## Cenário Alternativo: Validação Manual de Eventos Críticos

**Ações do Ator:**  
1. O Operador humano revisa eventos classificados como ameaça mas que não foram interceptados.
2. Corrige a classificação ou marca o evento como ambíguo.

**Ações do Sistema:**  
1. Incorpora o evento corrigido como dado de treino supervisionado.
2. Ajusta os pesos do modelo com base na intervenção humana.
3. Revalida o modelo atualizado.


## Cenário de Exceção: Modelo Aprendido Gera Resultado Pior

**Ações do Ator:**  
1. O Operador humano identifica aumento de falsos positivos após atualização de modelo.
2. Solicita reversão do modelo anterior.

**Ações do Sistema:**  
1. Detecta deterioração de desempenho nos relatórios de classificação.
2. Reverte para a versão anterior do modelo automaticamente.
3. Armazena o modelo rejeitado para análise posterior.
4. Notifica o Sistema de Controle de Defesa e o Operador humano sobre a reversão.
